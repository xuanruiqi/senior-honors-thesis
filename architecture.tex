\section{The architecture of Elephant Tracks}
\cite{ElephantTracks} listed six design goals of Elephant Tracks: precise, complete, informative,
well-defined, portable, and fast. However, the latest release of Elephant Tracks \citep{ElephantTracksPage}
barely achieves three of those goals, namely well-defined, portable and fast.

According to \cite{ElephantTracksPage}, the current release of Elephant Tracks fails to run on most Java
implementations (supporting only IBM J9), does not support recent Java implementations, and can be
irritatingly slow. Most of the problems bugging Elephant Tracks could be attributed to its architecture.

The old Elephant Tracks --- like the new Java frontend to Elephant Tracks --- is written as a JVM Tool Interface
agent \citep{ElephantTracks}. The JVMTI, according to Oracle's specifications, is a interface which should be implemented
by all standards-conforming JVMs that allow developers and debuggers to dynamically inspect and control the state
and execution of Java programs \citep{JVMTI} running in a JVM, in a fashion similar to the GNU Debugger
(\lstinline{gdb})'s state inspection and execution control facilities. For example, \lstinline{jdb}, the
\lstinline{gdb}-style debugger included in both of Oracle's Java implementations (Oracle JDK and OpenJDK), is implemented
as a JVMTI agent.

The JVMTI does not specify how the JVM shall interact with JVMTI agents besides stating that they should ``run in the same
process with and communicate directly with the virtual machine executing the application being examined''. However, since
JVMTI agents are compiled to native shared objects on the host system, most if not all JVM implementations dynamically
link with the JVMTI agent at runtime and call into the JVMTI agent at specific events. For example, a (rather primitive)
profiler might want to set a callback on the entry and exit of each method to generate a call graph. At run time, every time
a method is entered or exited, the JVM calls into the provided callback function and executes it. The JVMTI, therefore, is an
ideal technique to implement a memory tracer. Thus, when we designed the Java frontend for ET2, we chose to continue to use
the JVMTI as a portable and efficient technique to gather traces.

Elephant Tracks uses dynamic \emph{bytecode rewriting} as its major implementation technique. A JVMTI callback is set such that
Elephant Tracks gets access to a class's metadata and bytecode right before a class is loaded. Then, Elephant Tracks inspects
the bytecode of each method in the class, searching for important events such as object allocation (i.e. a \lstinline{new} instruction)
or a pointer update (usually a \lstinline{putfield} instruction). When an important event is found, the bytecode rewriter inserts a
call to a static method in a ``proxy'' class. After Elephant Tracks rewrite the class, it is loaded and executed. During
execution, the ``proxy'' method generates appropriate traces for the event it witnesses.

For example, let us consider the following Java method, taken from a real benchmark used to profile ET2:
\begin{lstlisting}[
    caption={Elephant Tracks example: source code},
    label={lst:1}, basicstyle=\small,
    frame=single,
    numbers=none,
    language=java]
  public class BinarySearchTree<T extends Comparable<T> > {
      // other methods omitted
    
      public void insert(T insertVal) {
          if (val == null) {
              val = insertVal;
              return;
          }

          if (val.compareTo(insertVal) <= 0) {
              if (right == null) {
                  right = new BinarySearchTree<T>(insertVal);
              } else {
                  right.insert(insertVal);
              }
          } else if (left == null) {
              left = new BinarySearchTree<T>(insertVal);
          } else {
              left.insert(insertVal);
          }
      }
  }
\end{lstlisting}

An analysis at the source code level would allow us to spot the allocation sites and pointer updates and
``liveness witnesses'' (i.e. instructions that proves the liveness of an object) in the code:
\begin{lstlisting}[
    caption={Elephant Tracks example: annotated source code},
    label={lst:1}, basicstyle=\small,
    frame=single,
    numbers=none,
    language=java]

  public class BinarySearchTree<T extends Comparable<T> > {
      // other methods omitted
      
      public void insert(T insertVal) {
          // witness the liveness of the callee of ``insert''
        
          if (val == null) {
              // pointer update: val -> insertVal
              val = insertVal;
              return;
          }

          if (val.compareTo(insertVal) <= 0) {
            if (right == null) {
                  // allocation and pointer update
                  right = new BinarySearchTree<T>(insertVal);
              } else {
                  right.insert(insertVal);
              }
          } else if (left == null) {
              // allocation and pointer update
              left = new BinarySearchTree<T>(insertVal);
          } else {
              left.insert(insertVal);
          }
      }
  }
\end{lstlisting}


Next, the bytecode of the \lstinline{compile} method shall be examined. The \lstinline{BinarySearchTree} class
is compiled using \lstinline{javac} version 1.8.0\_161 and then disassembled using \lstinline{javap}. Comments which mark the places where
Elephant Tracks would inject method calls have been inserted.
\begin{lstlisting}[
    caption={Elephant Tracks example: annotated bytecode},
    label={lst:1}, basicstyle=\small,
    frame=single,
    numbers=none,
    language=jvmis]
  public void insert(T);
      Code:
         0: aload_0
         1: getfield      #2  // Field val:Ljava/lang/Comparable;
         4: ifnonnull     13
         7: aload_0
         8: aload_1
         // pointer update
         9: putfield      #2  // Field val:Ljava/lang/Comparable;
        // method exit
        12: return
        13: aload_0
        14: getfield      #2  // Field val:Ljava/lang/Comparable;
        17: aload_1
        // liveness witness (``val'') & method call
        18: invokeinterface #6,  2  // InterfaceMethod java/lang/Comparable.compareTo:(Ljava/lang/Object;)I
        23: ifgt          59
        26: aload_0
        27: getfield      #4  // Field right:LBinarySearchTree;
        30: ifnonnull     48
        33: aload_0
        // allocation
        34: new           #7  // class BinarySearchTree
        37: dup
        38: aload_1
        // method call
        39: invokespecial #8  // Method "<init>":(Ljava/lang/Comparable;)V
        42: putfield      #4  // Field right:LBinarySearchTree;
        45: goto          89
        48: aload_0
        49: getfield      #4  // Field right:LBinarySearchTree;
        52: aload_1
        // liveness witness (``right'') & method call
        53: invokevirtual #9  // Method insert:(Ljava/lang/Comparable;)V
        56: goto          89
        59: aload_0
        60: getfield      #3  // Field left:LBinarySearchTree;
        63: ifnonnull     81
        66: aload_0
        // allocation
        67: new           #7  // class BinarySearchTree
        70: dup
        71: aload_1
        // method call
        72: invokespecial #8  // Method "<init>":(Ljava/lang/Comparable;)V
        // pointer update
        75: putfield      #3  // Field left:LBinarySearchTree;
        78: goto          89
        81: aload_0
        82: getfield      #3  // Field left:LBinarySearchTree;
        85: aload_1
        // liveness witness ("left") & method call
        86: invokevirtual #9  // Method insert:(Ljava/lang/Comparable;)V
        // method exit
        89: return
\end{lstlisting}

As one might see, there are two deciding factors that constrain Elephant Tracks' efficiency: the efficiency
of bytecode rewriting, and the number (and efficiency) of inserted method calls. However, these two aspects
are exactly the places where Elephant Tracks perform badly.

In the Elephant Tracks workflow, a JVMTI callback fetches the bytecode of a newly loaded class, and then launches
a rewriting procedure (using the ASM library) in a new JVM process. The communication between the Elephant Tracks
host JVM and the newly lanched Java process is facilitated using standard UNIX interprocess communication utilities.
Then, the rewriter inserts a number of instrumentation method calls to the program. However, the instrumentation calls
are JNI invocations, and this results in the abstraction barrier between the JVM and the underlying system being broken
frequently, resulting in many important JVM facilities (such as just-in-time compilation) becoming unusable. The overheads of
interprocess communication and JNI invocations, when combined, results in poor performance for Elephant Tracks.

For details on the design of Elephant Tracks, however, we shall direct readers to \cite{ElephantTracks}. The main point here is
that the design of Elephant Tracks is driven by implementation and unmodular, and thus it contains a few important flaws which
need to be rectified. Thus, to optimize the workflow of Elephant Tracks, we propose a new design that decouples separate tasks
involved in memory tracing.

\section{Overview of ET2 architecture}
Elephant Tracks II contains two major components: the trace-collecting frontend, and the death-time computing backend. The two
components are completely decoupled from each other; as long as the frontend generates complete program traces in a 
Elephant Tracks II-compatible format, the backend will be able to compute accurate death records for the program trace, while the
accuracy of death records is completely up to the accuracy of the frontend. In other words, the backend is completely agnostic
about the frontend: the language of the program being traced and the method used to do tracing is irrelevant when it comes to
death time computation.

Elephant Tracks II is primarily designed for Java and other languages running on the Java virtual machine. For the sake of simplicity,
we will refer to \emph{both} the backend and the JVM frontend as ``Elephant Tracks II'' without qualification. However, Elephant Tracks II is not limited
to Java and the JVM: a frontend could be implemented for any programming language that use heap allocation, pointers, and garbage collection
\emph{at the implementation level}. Haskell, for example, does not have pointers or a memory model at the language level as all data is
immutable; however, heap allocation and pointers are used by the Glasgow Haskell Compiler to implement functional closures and lazy evaluation.
Thus, it is possible to use Elephant Tracks with the \emph{GHC implementation} of Haskell \footnote{However, if there was ever a
  implementation of Haskell which does not use pointers and heap-allocated memory in its memory model, such as an implementation
  directly on a SECD machine, we will not be able trace Haskell programs in that implementation. Fortunately, all practical Haskell
  compilers targeting the von Neumann architecture need to use heap allocation and pointers.}. Although we did not implement a Haskell
frontend for ET2 in the work leading to this thesis, we will describe a model for adapting ET2 to functional programming systems in
\hyperref[chap:extensible]{chapter 5}.

The algorithms and strategies used by the backend to compute death times will be described in the \hyperref[chap:algoimp]{next chapter}. In
the rest of this chapter, we will mainly discuss the high-level design of ET2.

\section{The frontend: trace collector}
Memory tracing is inherently slow, and the trace collector is where most of the problem is at. However, to safely optimize trace collection, we must
first decouple the trace collection phase from the computation phase. In the Elephant Tracks II architecture, the implementation of the
frontend, or trace collector, is not defined. Instead, the implementer may select whichever implementation technique that is appropriate. For Java,
we have continued to use bytecode rewriting as our main technique. However, for a native code compiler-based languages implementation like the GHC,
building trace-generation into the runtime might be a more appropriate technique.

To calculate object death times, five types of traces are required: procedure entry, procedure exit, object allocation, pointer updates, and \emph{witness}. Each trace must have a \emph{timestamp} which is necessary for running Merlin. A timestamp in the context of
ET2 is a logical timestamp that impose a total ordering on events; examples of good candidates for timestamps are the total number of 
method entries and exits, or the total number of allocated bytes. A physical timestamp, however, is not recommended as the trace
collector slows down program execution substantially. However, in the presence of concurrency, a total ordering on events might not be
appropriate. In that case, we could potentially use techniques such as Lamport clocks \citep{LamportClock} to induce a partial ordering
on events; however, this is still an open research problem\footnote{We will revisit this problem in the
\hyperref[chap:conclusion]{final chapter}.}.

\subsection{Types of traces}
The procedure entry trace has the following format:

\begin{lstlisting}[
    frame=none,
    numbers=none]
  M <procedure-id> <receiver-object-id> <thread-id> <timestamp>
\end{lstlisting}

In case that the traced programming language is not object-oriented, or that the method is global (e.g. a static method in Java), the
\lstinline{receiver-object-id} should be 0. For a language without threading support, the thread ID could be 0.

A series of \lstinline{P} traces mark parameters to the called procedure, with one trace accompanying one parameter. The \lstinline{P}
record has the following format:

\begin{lstlisting}[
    frame=none,
    numbers=none]
  P <procedure-id> <param-object-id> <thread-id> <timestamp>
\end{lstlisting}

The procedure exit trace has a similar format, only with the \lstinline{M} replaced by an \lstinline{E}. A procedure might be
exited due to either returning from the procedure or a thrown exception (as implemented by \lstinline{throw} in Java and
\lstinline{raise} in ML), and ET2 does not discern between these different types of exits\footnote{Besides exceptions, other
  control operators, such as \lstinline{throw} in Standard ML of New Jersey, \lstinline{shift} in Racket and
  \lstinline{coroutine.yield} in Lua, can also result in a procedure being exited without properly returning from the procedure. These should
  also be treated as procedure exits.}.

The heap allocation trace has the following format:

\begin{lstlisting}[
    frame=none,
    numbers=none]
  <alloc-type> <object-id> <size> <type> <site> <length> <thread-id> <timestamp>
\end{lstlisting}

There are two types of allocations: an allocation is either ``singular'' (as in allocating a Java object) or ``block'' (as in
allocating a Java array). An array allocation (denoted by \lstinline{A}) is deemed to have occured when a logically contiguous
section of memory is allocated for a sequential, homogenous collection of objects (i.e. an array), and in all other cases an allocation is
singular (denoted by \lstinline{N}). The \lstinline{object-id} is an unique, numerical identifier which identifies a newly allocated
heap object, while \lstinline{site} is a globally unique, numerical identifier for each site at which allocation occurs. The
\lstinline{length} field is only needed for block allocations and represent the number of objects allocated in the allocation; for
singular allocations, this field shall be 0.

The pointer update trace, which is the most complex record of all, has the following format:

\begin{lstlisting}[
    frame=none,
    numbers=none]
  U <old-target-id> <object-id> <new-target-id> <field-id> <thread-id> <timestamp>
\end{lstlisting}

The \emph{pointer update} trace assumes the runtime memory model uses records of pointers (i.e. similar to Java classes or C structs), but
workarounds could be designed for similar memory models. A \lstinline{U} record denotes that a field (with ID \lstinline{field-id}) in an
object (with ID \lstinline{object-id}), which previously pointed to \lstinline{old-target-id}, now points to \lstinline{new-target-id}, where
both \lstinline{old-target-id} and \lstinline{new-target-id} are IDs for memory objects.

The most important, but least intuitive trace type, the \emph{witness} trace, has the following format:

\begin{lstlisting}[
    frame=none,
    numbers=none]
  W <object-id> <thread-id> <timestamp>
\end{lstlisting}

The \lstinline{W} trace tells us one and only one thing: a thread observed that an object is alive at a given time. What counts as being \emph{alive}
is implementation-defined, but it must only underestimate, and not overestimate liveness: otherwise, the trace computation will identify live objects
as being dead! For example, for our Java implementation, we used a rather conservative methodology: an object is alive whenever it is used explicitly in a
program, for example, when a field is accessed, when an instance method is invoked on the object, or when an reference the object is supplied as an
argument to a method. Note, for example, we only make conservative estimations: we only assume an object is alive up to the time it was used as a method
argument, and do not assume that the object stays alive throught the method (which, however, might be true unbeknownst to us).

Finally, there is a garbage collection trace that is generated on each invocation of the garbage collector, which simply tells us that the GC has been
invoked by a certain thread at a certain point in time:

\begin{lstlisting}[
    frame=none,
    numbers=none]
  G <thread-id> <timestamp>
\end{lstlisting}

However, the \lstinline{G} trace is optional, as the simulator could decide for itself when to start simulating a GC.

\subsection{Tracing a program}
In Elephant Tracks II, a program is traced as it is executed, and the program tracing frontend outputs the traces as the corresponding events occur. This
allows a program trace to fully and accurately capture the execution profile of a program during a certain run of the program. Again, the ET2 framework does
not define how the tracer should be implemented, thus we would leave discussion of our tracer for the \hyperref[chap:algoimp]{next chapter}. 

\section{The backend: GC simulator}
Different ET2 frontends designed for different runtime systems may have completely different implementations, but all of them share the same backend. The
backend could be thought of as a simple ``interpreter'' for the traces: essentially, it reads in a trace line by line, simulates the heap graph according
to the trace, simulates a garbage collection when prompted, and computes the death times of objects that have died since the last GC invocation.

The backend has three different phases that run alternately: the simulation phase and the computation phase.

\subsection{The simulation phase}
In the simulation phase, the simulator ``regenerates'' the program heap according to the \lstinline{N}, \lstinline{A}, and \lstinline{U} traces, and keeps
track the current execution environment by keeping a stack of procedure records according to the \lstinline{M} and \lstinline{E} traces. The regenerated
heap should have the same shape as the program's heap at runtime, if tracing is done correctly.

\subsection{The computation phase}
Whenever we reach a \lstinline{G} record in our trace (or, in the absence of such records, when a set of conditions trigger collection), the simulator enters
the computation phase. In the collection phase, the simulator simply deletes from the reconstructed heap graph all unreachable nodes following a simple
mark-sweep procedure.

However, since we do not have access to information about the program in the simulator besides what is available in the traces, the garbage collection roots
could not be known precisely. In the \hyperref[chap:algoimp]{next chapter} we will describe a few methods to approximate this collection phase.

As objects get garbage-collected, their death time would be computed using the Merlin algorithm. That is, the simulator tries to decide the ``precise'' death
time using a graph search. Again, we will leave the specifics to the \hyperref[chap:algoimp]{next chapter}.
