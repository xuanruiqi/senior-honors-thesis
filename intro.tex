\epigraph{\itshape A LISP programmer knows the value of everything, but the cost of nothing.}
         {---Alan J. Perlis, ``Epigrams on Programming'' (1982)}

\nocite{Epigrams}
         
\section{The cost of cost}
Most if not all reasonably experienced programmers would probably have programmed in a programming language with
manual memory management, especially C and C++. Few of those programmers would like to be reminded about the horrors
of debugging and facing memory bugs --- especially those caused by dangling pointers and memory leaks. Often times,
C programmers fail to know the \emph{value} of things --- this causes many memory bugs like dangling pointers and
out-of-bounds access. One must allocate the correct amount of memory and deallocate that memory at the right time ---
if the programmer ever makes a mistake, the value goes away.

In Perlis' time, programming in manually managed languages such as C, Fortran and Pascal was still the norm. However, had Perlis
lived through the 1990s, he would have rephrased his epigram as ``most programmers know the cost of nothing''.
For a Lisp --- and Java, Ruby or Haskell --- programmer, knowing the value of things are much easier. The days where an
off-by-one error may result in the program hitting garbage memory and giving out unexpected results were long gone, and, except
in the few cases where C programming is still necessary, the majority of programmers are using automatically (or at least
semi-automatically, as in the case of C++) managed languages.

Knowing the value of things is now much easier: structured, high-level programming languages have greatly decreased the chances
that inadvertent programmer errors result in fatal program errors. However, there is a trade-off in any engineering problem, and the
case of programming language choice is no exception. With these programming languages, the \emph{cost} of things become
largely unpredictable.

A Java or Haskell programmer might use heap-allocated, linked data structures, but they would never explicit allocate or deallocate
any memory. When the programmer creates a new class instance or a new algebraic data type instance, the runtime system manages the
allocation for the programmer. When the object becomes unreachable, the garbage collector finds it and calls \lstinline{free} for
the programmer. High level imperative programming languages like Java and functional programming languages Haskell thus allow programmers
to concentrate on value of the things, but as a ``side effect'', these programmers cease to understand the cost of things, which is
abstracted away from them. 

\section{Why cost matters}
Memory cost becomes intractable for those programmers. When programmers no longer understand the memory cost of program operations,
memory bugs and other issues might occur. For example, when a Java programmer creates a \lstinline{static} class member holding large
chunks of memory, or when they create streams and handles without closing them, memory leaks may occur. Here are two examples of
two Java programs that create memory leaks:

\begin{lstlisting}[
    caption={Java memory leak examples},
    label={lst:1}, basicstyle=\small,
    frame=single,
    numbers=none,
    language=java]
  // memory leak by static reference
  static List<Object> p = new ArrayList<>(33554432);
  
  // memory leak by held resource
  public void foo() {
      try {
          Connection conn = getConnection();
          // do something with the connection
          conn.close();
      } catch (Exception e) {
          // if an exception is thrown, close() is never called
          System.err.println("Error: " + e);
      }
  }
\end{lstlisting}

In C or C++, memory leaks are, despite being much more numerous, relatively easier to deal with as they are easier to spot and could
be found using tools like \lstinline{valgrind}. In most cases, a programmer only needs to find a \lstinline{malloc} call that is not paired
with a \lstinline{free} call. However, in Java, memory leaks are infrequent, but they are hidden and might have serious consequences if
not discovered. A Java programmer might know when and where their object is allocated, but they almost never know when their object dies.
Moreover, the garbage collection overhead adds an indeterminable cost to program execution; although there are effective methods to decrease
this cost with some programmer input \citep{NG2C, PrioritizedGC}, the ``why'' is often not adequately understood.

For a Scala or Haskell programmer, the situation might be even worse as the basic program operations do not directly map into
memory allocations and deallocations. In this case, it is extremely hard for programmers to understand, and sometimes impossible,
for programmers to analyze the cost of their program operations. Although functional programming languages are not designed to be
memory efficient, sometimes the cost of programs is simply too large to be ignored. For example, due to lazy evaluation and
the use of function closures, a simple red-black tree benchmark in Haskell allocates more than 3 gigabytes of memory on the heap
(see the \hyperlink[appendix:a]{Appendix} for the program). In comparison, both the Standard ML and OCaml versions of this benchmark, compiled using their
respective optimizing native-code compilers (MLton and \lstinline{ocamlopt}), allocate only about 1.6 gigabytes of memory, ostensibly due to
both SML and OCaml using eager evaluation. Most of the extra memory Haskell allocates is deallocated immediately, but at this scale,
the space cost of functional programs does deserve more comprehension.  

The goal of this thesis, therefore, is to help Lisp --- and Java, Scala, Haskell, etc. --- programmers overcome Perlis' epigram
by providing them with tools that can help them understand the cost of their programs precisely. More specifically, this thesis looks into the
dynamic analysis of the space cost of programs; that is, to help programmers understand the life and death of their heap objects
at runtime.

\section{Why memory tracing?}
To better understand memory usage patterns in programs and identify
potential memory bottlenecks, we could use dynamic analysis to generate memory traces, or records of lives and
deaths of objects dynamically allocated on the heap. With those records, one could fully understand the memory usage
patterns of automatically memory managed programs.
Memory and garbage collection tracing is of paramount importance to the analysis of memory performance in garbage-collected
languages. Experimental studies of memory behavior and garbage collector performance \citep{ScalaJava, Garbology} rely on
precise analysis made possible by GC tracers. Moreover, memory tracing can be useful for debugging memory bugs and potential leaks
\citep{MemInsight}. Finally, memory tracing can be used to analyze the finer parts of GC performance issues, such as average
latency, i.e., time lapsed between the death of an object and its eventual deallocation.


\section{Challenges with preexisting tools}
Despite the importance of memory tracing in the analysis of garbage collection and memory usage in managed languages, there have
been few tools available to perform this task. One preexisting tool, GCTrace, is available as a component of the Jikes RVM \citep{JikesRVM}. However,
the Jikes RVM has been of research interest only, and has been mostly superseded by HotSpot JVM even in that field. Moreover, GCTrace
is built into the Jikes RVM and updates to the JVM itself has rendered it unusable in newer versions of Jikes RVM. Thus, GCTrace had
mostly fell into disuse. Another tool, Elephant Tracks \citep{ElephantTracks}, comes from our previous work, and was designed with
the goal to be portable between different JVMs in mind; in practice, Elephant Tracks has proved to be a relatively trustworthy tool.

However, Elephant Tracks has three fatal flaws. First, Elephant Tracks is not well documented and standardized, so its trace output
format and code base could bit-rot quickly, and as a result often fails its design goal of portability. Second, Elephant Tracks can
only provide GC trace analysis for JVM languages as the death record generalization process is built in to the running Java program
as a JVM agent. Finally, Elephant Tracks, although precise, is extremely slow: in usual cases, Elephant Tracks slows down program execution
by 500-1000 times, making full analysis of larger programs impossible. Although Elephant Tracks has been a good tool for controlled
experiments on the Java GC, its usage is severely limited by performance and portability issues.


\section{Presenting a new tool}
Although efforts were made to refine Elephant Tracks, it proved difficult to substantially improve the tool. Specifically, Elephant Tracks
has many outdated dependencies with legacy APIs, and updating the dependencies requires substantial engineering effort. Moreover,
Elephant Tracks suffers from a significant architectural flaw: Merlin, the algorithm used to produce death timestamps,
is run during the trace collection phase. Naturally, this slows down program execution and limits attempts to enhance the extensibility
of Elephant Tracks. As a result, the only choice left is to mostly scrape Elephant Tracks and re-design Elephant Tracks from scratch
(while reusing some components of the old Elephant Tracks), hence our tool is named Elephant Tracks II. While running the same algorithms and
using the same trace-gathering mechanics as Elephant Tracks, Elephant Tracks II is architecturally very different from the original Elephant
Tracks.

In this thesis, we will present \emph{Elephant Tracks II} (ET2), a practical, extensible GC tracing tool and memory analysis framework that inherits many of
the goals of Elephant Tracks, but which is also substantially different from Elephant Tracks in many ways; ET2 could thus be considered
a successor to Elephant Tracks. 


\section{Goals of the Elephant Tracks II project}
The goals of the Elephant Tracks II project directly address the shortcomings of Elephant Tracks. The main design and implementation
goals of Elephant Tracks II are as following:

\begin{enumerate}
\item \textbf{standardization}: provide a standard interface to and output format for GC traces;
\item \textbf{efficiency}: be as fast as possible, with the goal being a 50-100 $\times$ slowdown (as compared to
  Elephant Tracks' 500-1000 $\times$ slowdown, this is really fast!);
\item \textbf{modularity}: be as modular as possible. Especially, we would like to decouple the Merlin algorithm from the
  JVM agent, moving it into the ``postmortem'' analysis phase, which does not affect program execution;
\item \textbf{inter-language operability}: a result of the improved modularity, the new Elephant Tracks II trace analyzer can
  now analyze GC traces from any language in principle.
\end{enumerate}

\section{Collaboration}
Elephant Tracks II is a large project and is certainly not the work of one person. I did most of the design and the implementation of the
Java bytecode rewriter, but many the tracing algorithms were devised in collaboration with Samuel Guyer, while the backend was
written by Leandro Watanabe during his internship at Google based on code previously written by Samuel Guyer and Nathan Ricci. A team
of researchers from Google and the Australian National University collaborated on the Elephant Tracks II project in general, although much of the
work is not in the scope of this thesis.

\section{Outline of the thesis}
The thesis will be divided into six chapters, excluding this introductory chapter. \hyperref[chap:prelim]{Chapter 2} will introduce the premliminaries and
past work, including the Merlin algorithm \citep{Merlin}, memory tracing techniques, and issues with earlier GC tracer designs,
especially issues concerning the design of the original Elephant Tracks. \hyperref[chap:arch]{Chapter 3} will outline the architecture, trace format and
major design concerns in the design of Elephant Tracks 2. \hyperref[chap:algoimp]{Chapter 4} will discuss the implementation of Elephant Tracks II, including
the major programming techniques and strategies used to deal with difficult situations. \hyperref[chap:extensible]{Chapter 5} will discuss the extensibility of
Elephant Tracks II, especially to functional programming languages. \hyperref[chap:conclusion]{Chapter 6} will provide a comparison to other work and outline
future work. \hyperref[chap:realconclusion]{Chapter 7} will conclude the thesis.
